import (
  summaryWriter "summary_writer"
  mnistFormat   "mnist_data"

  tf            "tensorflow:"
  nn            "tensorflow:nn"
  summary       "tensorflow:summary"
  train         "tensorflow:train"
)

func convLayer(input, weights, biases) {
  input
  nn.conv2d[
    strides: [1, 1, 1, 1],
    padding: "SAME",
  ](^, weights)
  nn.bias_add(^, biases)
  nn.relu(^)
  nn.max_pool[
    ksize: [1, 2, 2, 1],
    strides: [1, 2, 2, 1],
    padding: "SAME",
  ](^)
  emit s = ^
}

func makeNn[] {
  // 5x5 filter, depth 32. Could also specify attr "seed"
  var conv1_weights float <5, 5, 1, 32> = tf.truncated_normal[shape: <5, 5, 1, 32>, stddev: 0.1]()
  var conv1_biases float <32> = 0
  var conv2_weights float <5, 5, 32, 64> = tf.truncated_normal[shape: <5, 5, 32, 64>, stddev: 0.1]()
  var conv2_biases float <64> = 0.1
  // Fully connected, depth 512
  // IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64
  var fc1_weights float <3136, 512> = tf.truncated_normal[shape: <3136, 512>, stddev: 0.1]()
  var fc1_biases float <512> = 0.1
  var fc2_weights float <512, 10> = tf.truncated_normal[shape: <512, 10>, stddev: 0.1]()
  var fc2_biases float <10> = 0.1

  func (input) {
    input
    convLayer(^, conv1_weights, conv1_biases)
    convLayer(^, conv2_weights, conv2_biases)
    tf.reshape(^, {-1, 3136})

    // Fully connected layer. Note that the '+' operation automatically
    // broadcasts the biases.
    tf.matmul(^, fc1_weights)
    ^ + fc1_biases
    nn.relu(^)
    tf.matmul(^, fc2_weights)
    ^ + fc2_biases
    <- r = ^
  }

  emit x = ^
}

}

graph testMnistFormat {
  imagesFile = "../MNIST_data/train-images-idx3-ubyte.gz"
  labelsFile = "../MNIST_data/train-labels-idx1-ubyte.gz"

  // Load images file
  mnistFormat.ReadImages(imagesFile) -- allImages
  mnistFormat.ReadLabels(labelsFile) -- allLabels

  // Make new queue, add mnist data to it.
  train.input_producer[element_shape: <784>](allImages) -- imageQ
  train.input_producer[element_shape: <10>](allLabels) -- labelQ

  imageQ:queue_ref -- imageQRef
  labelQ:queue_ref -- labelQRef

  myNn = makeNn[]

  f = for step int32 <> = 0; step < 20 {
    batchSize = 100
    nao.dequeue_many[component_types: {tf.float32}](labelQRef, batchSize) -- labels
    nao.dequeue_many[component_types: {tf.float32}](imageQRef, batchSize) -- images

    reshapedImages = tf.reshape(images, [-1, 28, 28, 1])
    summary.image(reshapedImages) -- imageSummary
    summaryWriter.Add(imageSummary) -- x

    reshapedImages
    myNn(^)
    tf.argmax(^, 1)
    tf.to_int32(^)
    tf.dynamic_partition[
      num_partitions: 10,
    ](reshapedImages, ^) -- partitionedImages

    summary.image(partitionedImages:0) -- image0s
    summaryWriter.Add(image0s)
    summary.image(partitionedImages:1) -- image1s
    summaryWriter.Add(image1s)
    summary.image(partitionedImages:2) -- image2s
    summaryWriter.Add(image2s)
    summary.image(partitionedImages:3) -- image3s
    summaryWriter.Add(image3s)

    <- step int32 <> = after __leaves { step + 1 }
  }

  <- x = f:step

  ← result = after __leaves { 1 }
}
